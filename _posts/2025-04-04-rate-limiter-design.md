---
title: "처리율 제한 장치(Rate Limiter) 설계하기"
excerpt: "네트워크 시스템에서 처리율을 제한하려면 무엇을 고려해야 할까?"

categories:
  - TIL
tags:
  - [Rate Limiter, 처리율 제한]

permalink: /til/rate-limiter-design/

toc: true
# toc_sticky: true

date: 2025-04-04
last_modified_at: 2025-04-04
---

> 가상 면접 사례로 배우는 대규모 시스템 설계 기초 4장을 읽고 정리한 글입니다.
<br>

## 처리율 제한 장치 (Rate Limiter = API Throttling)

네트워크 시스템에서 처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽 처리율(rate)을 제한하기 위한 장치이다. 보통은 트래픽 부하를 분산시키기 위해 로드밸런서를 사용하지만 그럼에도 처리율 제한은 필요하다.   
<br>   
처리 제한 규칙 예시

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 동일 계정으로 주 5회 이상의 리워드를 요청할 수 없다.

<br>   

### 왜 처리율 제한 장치가 필요할까?

- Dos 공격에 의한 자원 고갈(resource starvation)을 방지하기 위함
- 처리율을 제한하여 서버를 많이 두지 않아도 되고, 우선 순위가 높은 API에 더 많은 자원을 할당하는 방식으로 서버 리소스를 절감
- 사용자의 잘못된 이용 패턴으로 인해 유발된 트래픽을 걸러내 서버 과부하 방지

<br>

처리율 제한 장치를 구현하기 위해 고려해야 할 점들은 다음과 같다.

- 처리율을 어디서 제어해야 하는지
    - 클라이언트 측 제한 장치
    - 서버 측 제한 장치
- 처리 제어 기준
    - IP 주소를 기준으로 삼음
    - 사용자 ID를 기준으로 삼음
    - API 엔드 포인트나 서비스 단위
- 시스템의 규모
- 분산 환경에서도 동작 가능한지
- 사용자의 요청이 제한 장치에 의해 걸러졌을 때 사용자 측에서 알아야 하는지

<br>

### 처리율은 어디서 제어되어야 할까?

| 위치 | 장점 | 단점 |
| --- | --- | --- |
| 클라이언트 측 | 없음 | - 위변조가 쉽다.<br>- 모든 클라이언트의 구현을 통제하기 어렵다. |
| 미들웨어 측 | 처리율 제한을 지원하는 API gateway를 두어 쉽게 구현할 수 있다. | - 커스텀하기 어려울 수 있다. |
| 서버 측 | 자유롭게 처리율 제한 알고리즘을 선택할 수 있다. | - 처리율 제한 장치 구현 인력이 추가로 필요하다. |

만약 설계가 MSA에 기반하고 있고 API gateway를 이미 설계에 포함시켰거나
처리율 제한 장치를 구현할 리소스나 시간이 충분하지 않다면 상용 API gateway에서 지원하는 처리율 제한 장치를 구현하는 것이 바람직한 방법일 것이다.

<br>

### 처리율 제한 알고리즘

| 이름 | 토큰 버킷(token bucket) | 누출 버킷(leaky bucket) |
| --- | --- | --- |
| 동작 원리 | 지정된 용량을 갖는 버킷에서 요청을 처리할 때마다 토큰을 꺼내 사용하는 방식.<br>토큰이 없다면 요청은 버려진다. (dropped) | 큐에 자리가 있는지 확인한 후, 빈 자리가 있으면 요청을 추가한다.<br>큐가 가득 찼다면 요청은 버려진다. |
| 특징 | 간단하고 세간의 이해도도 높아 폭넓게 사용된다. | 요청 처리율이 고정된 FIFO 큐로 구현 |
| 장점 | - 구현 쉽고 메모리 효율적<br>-짧은 시간에 집중되는 트래픽 커버 가능<br>- 버킷에 토큰이 남았다면 요청이 무조건 시스템에 전달된다. | - 고정 속도로 처리하기 때문에 안정적 출력이 가능하다.<br>- 큐 크기가 제한되어 있어 메모리 효율적 |
| 단점 | - 버킷 크기와 토큰 공급률을 정하기 까다롭다.(제어 조건을 IP 주소로 할 것인지, 초당 요청 수로 할 것인지에 따라 버킷 관리가 달라짐) | - 단시간 많은 트래픽이 몰릴 경우, 이전 요청을 처리하지 못하고 쌓임에 따라 새 요청이 버려질 수 있다.<br>- 버킷 크기와 처리율을 정하기 까다롭다. |

| 이름 | 고정 윈도우 카운터(fixed window counter) | 이동 윈도우 로깅(sliding window logging) | 이동 윈도우 카운터(sliding window counter) |
| --- | --- | --- | --- |
| 동작 원리 | 타임라인을 고정 간격의 윈도우로 나누고, 윈도우마다 카운터를 붙인다.<br>카운터가 임계치에 도달하면 요청은 새 윈도우가 열릴 때까지 버려진다. | 요청의 타임스탬프를 이용해, 새 요청이 오면 만료된 타임스탬프를 제거하고 신규 요청의 타임스탬프를 로그에 추가한다.<br>로그의 크기가 허용치보다 커지면 요청은 버려진다. | 현재 1분 간의 요청 수 + 직전 1분 간의 요청 수 * 이동 윈도우와 직전 1분이 겹치는 비율을 이용해 현재 윈도우의 요청 수를 계산한다. |
| 특징 |  | 고정 윈도우의 윈도우 부근 트래픽 문제 해결 | 고정 윈도우 카운터 + 이동 윈도우 로깅 |
| 장점 | - 메모리 효율적<br>- 특정 패턴의 트래픽을 처리하기에 적합 | - 고정 속도로 처리하기 때문에 안정적 출력이 가능하다.<br>- 큐 크기가 제한되어 있어 메모리 효율적 | - 메모리 효율적<br>- 버스트 트래픽에 대응하기 좋음 |
| 단점 | - 윈도우 경계 부근에 일시적인 트래픽이 발생할 경우, 기대했던 처리 한도를 초과할 수 있다. | - 단시간 많은 트래픽이 몰릴 경우, 이전 요청을 처리하지 못하고 쌓임에 따라 새 요청이 버려질 수 있다.- 버킷 크기와 처리율을 정하기 까다롭다. | - 직전 시간대 요청이 균등하게 분포되어 있다고 가정하기에 비교적 느슨하다. |

처리율 제한 알고리즘은 추적 대상별 카운터를 생성하고, 카운터의 한도를 넘어서면 이후 요청은 거부하는 매커니즘을 기반으로 동작한다. 카운터는 어디에 보관하는 것이 적절한가?

보통 데이터베이스를 떠올리겠지만 디스크에 접근해야 하기 때문에 사용하면 안 될 것이다. 시간에 기반한 만료 정책을 지원하는 메모리 상에서 동작하는 캐시를 사용하는 것이 바람직하겠다. 보통 메모리 기반 저장 장치인 **Redis**의 INCR, EXPIRE 두 가지 명령어를 사용하여 처리율 제한 장치 구현 방식을 많이 사용한다.

<br>

### 처리가 제한된 요청들은 어떻게 처리할 것인가?

어떤 요청이 한도 제한에 걸리면 API는 HTTP 429 응답(too many request)을 클라이언트에 보낸다. 경우에 따라서 한도 제한에 걸린 메시지를 나중에 처리하기 위해 큐에 보관할 수도 있겠다.

<br>

클라이언트는 요청이 처리율 제한에 걸리고 있는지 어떻게 감지할 수 있을까?
HTTP Header를 통해 클라이언트에게 overflow 되었다고 전달한다. 이를 관리하는 HTTP Header 종류는 다음과 같다.

| X-Ratelimit-Limit | X-Ratelimit-Remaining | X-Ratelimit-Retry-After | X-Ratelimit-Reset | X-Daily-Requests-Left |
| --- | --- | --- | --- | --- |
| 클라이언트가 보낼 수 있는 API별 총 요청 한도. | 남은 API 요청 횟수. 이 횟수 만큼 추가 요청을 보낼 수 있다. | 다음 API 요청을 시도하기 전에 대기해야 하는 시간 | 요청 최댓값이 재설정 될 때까지의 시간 | API 요청에서 사용 가능한 남은 일일 요청 횟수 |

클라이언트가 요청을 보내면 미들웨어는 Redis를 이용해 한도를 검사하고 요청을 처리한다. 이 과정에서 처리율 제한에 걸린 요청은 429 에러를 반환한다.

<br>

### 분산 환경에서는 문제가 없을까?

여러 대의 서버와 병렬 스레드를 지원하도록 설계된 시스템에서 처리율을 제한할 때에는 추가로 고려해야 할 상황이 있다.

- 경쟁조건(race condition)
    
    두 개의 요청을 처리하는 스레드가 각각 병렬로 카운터 값을 읽고 카운터에 1을 추가한 값을 저장하는 상황에서 다른 요청의 처리 상태를 상관하지 않아 카운터의 값이 누락될 수 있다.
    
    해결책으로 Lock을 사용할 수 있겠지만 시스템의 성능을 떨어뜨리는 문제가 있다. 락 대신 Lua Script 또는 Redis의 정렬 집합(Sorted Set)을 사용한다.
    
- 동기화 이슈
    
    처리율 제한 장치 서버를 여러 대 두었을 경우, 웹 계층은 무상태(stateless)이므로 동일한 클라이언트에 대한 요청이 다른 제한 장치에 전달될 때 동기화되어 있지 않다면 올바르게 수행할 수 없을 것이다.
    
    고정 세션(sticky session)을 활용하여 같은 클라이언트의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있다. 하지만 규모 면에서 확장 가능하지도 유연하지도 않기 때문에 추천하지 않는다.
    
    더 나은 해결책으로 Redis의 중앙 집중형 데이터를 저장할 수 있다.
    

이 말고도 성능 최적화, 모니터링 등 상세 설계에 대해 고민해볼 것들이 많다.

<br>

### 마무리

처리율 제한 장치에서 사용하는 알고리즘 기법과 설계 시 고려해야 할 점을 알아보았다. 다음에는 Spring Boot에서 처리율 제한 장치를 구현하는 방법을 다뤄볼 것이다.
